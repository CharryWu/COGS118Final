{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T04:00:00.421197Z",
     "start_time": "2018-03-26T04:00:00.384224Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Constants and Methods - change this if adding new models/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T03:48:42.501402Z",
     "start_time": "2018-03-26T03:48:42.463893Z"
    }
   },
   "outputs": [],
   "source": [
    "CUTOFF_SIZE = 5000\n",
    "K_LIST_SIZE = 26\n",
    "\n",
    "TEST_PARTITION_PERCENTAGES = [0.2,0.5,0.8]\n",
    "\n",
    "NUM_MODELS = 4\n",
    "NUM_DATASETS = 3\n",
    "NUM_PARTITIONS = len(TEST_PARTITION_PERCENTAGES)\n",
    "NUM_TRIALS = 3\n",
    "\n",
    "# Encode all attributes values in accuracy table\n",
    "KNN=0\n",
    "SVM=1\n",
    "LR=2\n",
    "RF=3\n",
    "\n",
    "PART_TEST_20=0\n",
    "PART_TEST_50=1\n",
    "PART_TEST_80=2\n",
    "\n",
    "ADULT=0\n",
    "COV=1\n",
    "LETTER=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy table is indexed as follows: \n",
    "# ACCU_TABLE[MODEL][DSET][PART][TRIAL]\n",
    "# e.g.: ACCU_TABLE[KNN][ADULT][PART_TEST_50][2] = (train_acc,val_acc,test_acc)\n",
    "# ---------------- Running this cell will clear all data! ----------------\n",
    "ACCU_TABLE = np.zeros((NUM_MODELS,\n",
    "                       NUM_DATASETS,\n",
    "                       NUM_PARTITIONS,\n",
    "                       NUM_TRIALS), \n",
    "                       dtype=object)\n",
    "BEST_PARAM_TABLE = np.zeros((NUM_MODELS,\n",
    "                             NUM_DATASETS,\n",
    "                             NUM_PARTITIONS,\n",
    "                             NUM_TRIALS),\n",
    "                             dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:44:52.901157Z",
     "start_time": "2018-03-25T19:44:52.889600Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_shapes(*args):\n",
    "    for arg in args:\n",
    "       print(arg.shape)\n",
    "\n",
    "def ___():\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "def __():\n",
    "    print(\"-\"*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:44:54.247203Z",
     "start_time": "2018-03-25T19:44:54.237822Z"
    }
   },
   "outputs": [],
   "source": [
    "def store_acc_param(model_idx, \n",
    "                    dset_idx, \n",
    "                    part_idx,\n",
    "                    trial_idx,\n",
    "                    best_param,\n",
    "                    train_acc,\n",
    "                    val_acc,\n",
    "                    test_acc): \n",
    "    BEST_PARAM_TABLE[model_idx][dset_idx][part_idx][trial_idx] = \\\n",
    "        best_param\n",
    "    ACCU_TABLE[model_idx][dset_idx][part_idx][trial_idx] = \\\n",
    "        (train_acc, val_acc, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:45:02.656068Z",
     "start_time": "2018-03-25T19:44:56.168317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adult dataset\n",
    "adult_set = pd.read_csv('adult.data', header=None,\n",
    "                        skipinitialspace=True)\n",
    "adult_set = adult_set[~adult_set.eq('?').any(1)] # data cleaning\n",
    "adult_set = shuffle(adult_set)[:CUTOFF_SIZE]\n",
    "\n",
    "# Covtype dataset\n",
    "covtype_set = pd.read_csv('covtype.data', header=None,\n",
    "                          skipinitialspace=True)\n",
    "covtype_set = shuffle(covtype_set)[:CUTOFF_SIZE]\n",
    "\n",
    "# Letter dataset\n",
    "letter_set = pd.read_csv('letter-recognition.data.txt', header=None,\n",
    "                         skipinitialspace=True)\n",
    "letter_set = shuffle(letter_set)[:CUTOFF_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:45:03.702367Z",
     "start_time": "2018-03-25T19:45:03.694847Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 15)\n",
      "(5000, 55)\n",
      "(5000, 17)\n"
     ]
    }
   ],
   "source": [
    "# check shape of matrix\n",
    "print_shapes(adult_set,covtype_set,letter_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:45:05.508025Z",
     "start_time": "2018-03-25T19:45:05.472166Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    3762\n",
      "True     1238\n",
      "Name: 14, dtype: int64\n",
      "--------------------------------------------------\n",
      "2    2470\n",
      "1    1782\n",
      "3     345\n",
      "7     160\n",
      "6     152\n",
      "5      67\n",
      "4      24\n",
      "Name: 54, dtype: int64\n",
      "-------------------------\n",
      "False    2530\n",
      "True     2470\n",
      "Name: 54, dtype: int64\n",
      "--------------------------------------------------\n",
      "True     2508\n",
      "False    2492\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Pos-Neg dataset splitting criteria\n",
    "print((adult_set[adult_set.shape[1] - 1] == \">50K\").value_counts())\n",
    "___()\n",
    "# 2 is the most cover type, choose it to be true\n",
    "print(covtype_set[covtype_set.shape[1] - 1].value_counts()) \n",
    "__()\n",
    "print((covtype_set[covtype_set.shape[1] - 1] == 2).value_counts())\n",
    "___()\n",
    "print((letter_set[0] <= 'M').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:45:07.692557Z",
     "start_time": "2018-03-25T19:45:07.460457Z"
    }
   },
   "outputs": [],
   "source": [
    "# label pos/neg data\n",
    "adult_set[adult_set.shape[1] - 1] = adult_set[adult_set.shape[1] - 1] == \">50K\"\n",
    "covtype_set[covtype_set.shape[1] - 1] = covtype_set[covtype_set.shape[1] - 1] == 2\n",
    "letter_set[0] = letter_set[0] <= 'M' # y is the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:45:08.615555Z",
     "start_time": "2018-03-25T19:45:08.609293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 15)\n",
      "(5000, 55)\n",
      "(5000, 17)\n"
     ]
    }
   ],
   "source": [
    "print_shapes(adult_set,covtype_set,letter_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:45:10.811523Z",
     "start_time": "2018-03-25T19:45:10.393495Z"
    }
   },
   "outputs": [],
   "source": [
    "# subsets to feed into models\n",
    "adult_X_trains = []\n",
    "adult_X_tests = []\n",
    "adult_Y_trains = []\n",
    "adult_Y_tests = []\n",
    "\n",
    "cov_X_trains = []\n",
    "cov_X_tests = []\n",
    "cov_Y_trains = []\n",
    "cov_Y_tests = []\n",
    "\n",
    "letter_X_trains = []\n",
    "letter_X_tests = []\n",
    "letter_Y_trains = []\n",
    "letter_Y_tests = []\n",
    "\n",
    "# adult_X_trains is of size 9 = 3 trials * 3 partitions\n",
    "\n",
    "# PRECONDITION:\n",
    "# adult_set.shape[0] == covtype.shape[0] == letter_set.shape[0] == 5000\n",
    "for i in range(NUM_TRIALS):\n",
    "    adult_set = shuffle(adult_set)\n",
    "    covtype_set = shuffle(covtype_set)\n",
    "    letter_set = shuffle(letter_set)\n",
    "    \n",
    "    adult_X = adult_set.loc[:,:13]; adult_Y = adult_set.loc[:,14]\n",
    "    cov_X = covtype_set.loc[:,:53]; cov_Y = covtype_set.loc[:,54]\n",
    "    letter_X = letter_set.loc[:,1:]; letter_Y = letter_set.loc[:,0]\n",
    "\n",
    "    adult_X = pd.get_dummies(adult_X)\n",
    "    cov_X = pd.get_dummies(cov_X)\n",
    "    letter_X = pd.get_dummies(letter_X)\n",
    "    \n",
    "    for part_percent in [0.2,0.5,0.8]:\n",
    "        \n",
    "        # working on adult dataset\n",
    "        adult_X_train, adult_X_test, adult_Y_train, adult_Y_test = \\\n",
    "            train_test_split(adult_X, adult_Y, test_size=part_percent)\n",
    "\n",
    "        adult_X_trains.append(adult_X_train)\n",
    "        adult_X_tests.append(adult_X_test)\n",
    "        adult_Y_trains.append(adult_Y_train)\n",
    "        adult_Y_tests.append(adult_Y_test)\n",
    "    \n",
    "        # working on cov dataset\n",
    "        cov_X_train, cov_X_test, cov_Y_train, cov_Y_test = \\\n",
    "            train_test_split(cov_X, cov_Y, test_size=part_percent)\n",
    "\n",
    "        cov_X_trains.append(cov_X_train)\n",
    "        cov_X_tests.append(cov_X_test)\n",
    "        cov_Y_trains.append(cov_Y_train)\n",
    "        cov_Y_tests.append(cov_Y_test)\n",
    "    \n",
    "        # working on letter dataset\n",
    "        letter_X_train, letter_X_test, letter_Y_train, letter_Y_test = \\\n",
    "            train_test_split(letter_X, letter_Y, test_size=part_percent)\n",
    "\n",
    "        letter_X_trains.append(letter_X_train)\n",
    "        letter_X_tests.append(letter_X_test)\n",
    "        letter_Y_trains.append(letter_Y_train)\n",
    "        letter_Y_tests.append(letter_Y_test)\n",
    "    \n",
    "# POSTCONDITION:\n",
    "# after the above process dataset lists becomes\n",
    "# - trial 1\n",
    "#   - [0]part1 (80% data)\n",
    "#   - [1]part2 (50% data)\n",
    "#   - [2]part3 (20% data)\n",
    "# - trial 2\n",
    "#   - [3]part1 (80% data)\n",
    "#     ...\n",
    "# with each input subset having 9 = 3 trials * 3 partition entries\n",
    "# with a total of 9 such input subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:43:46.753794Z",
     "start_time": "2018-03-25T19:43:45.068Z"
    }
   },
   "outputs": [],
   "source": [
    "# reorder the datasets into\n",
    "# - part 1\n",
    "#   - [0]part1_trial1 (80% data)\n",
    "#   - [1]part1_trail2 (80% data)\n",
    "#   - [2]part1_trail3 (80% data)\n",
    "# - part 2\n",
    "#   - [3]part2_trial1 (50% data)\n",
    "#     ...\n",
    "\n",
    "# mylist=['a','b','c','d','e']\n",
    "# myorder=[3,2,0,1,4]\n",
    "# mylist = [ mylist[i] for i in myorder] #// mylist becomes [d,c,a,b,e]\n",
    "# print mylist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "CV_FOLD = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T02:30:03.400821Z",
     "start_time": "2018-03-26T02:22:09.713190Z"
    }
   },
   "outputs": [],
   "source": [
    "# KNN on adult dataset \n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        adult_X_train = adult_X_trains[data_idx]\n",
    "        adult_X_test = adult_X_tests[data_idx]\n",
    "        adult_Y_train = adult_Y_trains[data_idx]\n",
    "        adult_Y_test = adult_Y_tests[data_idx]\n",
    "        \n",
    "        # K_list elements varies by train size so need to be put inside loop\n",
    "        K_list = np.linspace(start=1,\n",
    "                             stop=adult_X_train.shape[0] * (1-1/CV_FOLD),\n",
    "                             num=K_LIST_SIZE).astype(int) # because we are doing 3 fold cv\n",
    "        knn_param = {'n_neighbors':K_list}\n",
    "        \n",
    "        clf_knn = GridSearchCV(KNeighborsClassifier(algorithm=\"brute\"), \n",
    "                               knn_param, \n",
    "                               cv=CV_FOLD,\n",
    "                               return_train_score=True)\n",
    "        clf_knn.fit(adult_X_train, adult_Y_train)\n",
    "        \n",
    "        store_acc_param(KNN,ADULT,part_itr,trial_itr,\n",
    "                        clf_knn.best_params_,\n",
    "                        clf_knn.cv_results_['mean_train_score'][clf_knn.best_index_],\n",
    "                        clf_knn.cv_results_['mean_test_score'][clf_knn.best_index_],\n",
    "                        clf_knn.score(adult_X_test,adult_Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T21:09:07.744304Z",
     "start_time": "2018-03-25T21:02:09.524991Z"
    }
   },
   "outputs": [],
   "source": [
    "# KNN on cov dataset \n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        cov_X_train = cov_X_trains[data_idx]\n",
    "        cov_X_test = cov_X_tests[data_idx]\n",
    "        cov_Y_train = cov_Y_trains[data_idx]\n",
    "        cov_Y_test = cov_Y_tests[data_idx]\n",
    "        \n",
    "        # K_list elements varies by train size so need to be put inside loop\n",
    "        K_list = np.linspace(start=1,\n",
    "                             stop=cov_X_train.shape[0] * (1-1/CV_FOLD),\n",
    "                             num=K_LIST_SIZE).astype(int) # because we are doing 3 fold cv\n",
    "        knn_param = {'n_neighbors':K_list}\n",
    "        \n",
    "        clf_knn = GridSearchCV(KNeighborsClassifier(algorithm=\"brute\"), \n",
    "                               knn_param, \n",
    "                               cv=CV_FOLD,\n",
    "                               return_train_score=True)\n",
    "        clf_knn.fit(cov_X_train, cov_Y_train)\n",
    "        \n",
    "        store_acc_param(KNN,COV,part_itr,trial_itr,\n",
    "                        clf_knn.best_params_,\n",
    "                        clf_knn.cv_results_['mean_train_score'][clf_knn.best_index_],\n",
    "                        clf_knn.cv_results_['mean_test_score'][clf_knn.best_index_],\n",
    "                        clf_knn.score(cov_X_test,cov_Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T21:39:50.223609Z",
     "start_time": "2018-03-25T21:33:00.446800Z"
    }
   },
   "outputs": [],
   "source": [
    "# KNN on letter dataset \n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        letter_X_train = letter_X_trains[data_idx]\n",
    "        letter_X_test = letter_X_tests[data_idx]\n",
    "        letter_Y_train = letter_Y_trains[data_idx]\n",
    "        letter_Y_test = letter_Y_tests[data_idx]\n",
    "        \n",
    "        # K_list elements varies by train size so need to be put inside loop\n",
    "        K_list = np.linspace(start=1,\n",
    "                             stop=letter_X_train.shape[0] * (1-1/CV_FOLD),\n",
    "                             num=K_LIST_SIZE).astype(int) # because we are doing 3 fold cv\n",
    "        knn_param = {'n_neighbors':K_list}\n",
    "        \n",
    "        clf_knn = GridSearchCV(KNeighborsClassifier(algorithm=\"brute\"), \n",
    "                               knn_param, \n",
    "                               cv=CV_FOLD,\n",
    "                               return_train_score=True)\n",
    "        clf_knn.fit(letter_X_train, letter_Y_train)\n",
    "        \n",
    "        store_acc_param(KNN,LETTER,part_itr,trial_itr,\n",
    "                        clf_knn.best_params_,\n",
    "                        clf_knn.cv_results_['mean_train_score'][clf_knn.best_index_],\n",
    "                        clf_knn.cv_results_['mean_test_score'][clf_knn.best_index_],\n",
    "                        clf_knn.score(letter_X_test,letter_Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T21:46:28.748554Z",
     "start_time": "2018-03-25T21:46:28.739260Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "C_list_svm     = [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1, 1, 10, 100, 1000] # Different C to try.\n",
    "widths = np.array([0.001,0.005,0.01,0.05,0.1,0.5,1,2])\n",
    "gammas = 1/np.sqrt(widths*2)\n",
    "\n",
    "svm_params_linear = {\n",
    "    'C':C_list_svm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T20:35:13.527764Z",
     "start_time": "2018-03-25T20:33:56.389263Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charry/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/charry/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/charry/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/charry/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/charry/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/charry/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/charry/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/charry/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/charry/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# SVM on adult dataset\n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        adult_X_train = preprocessing.scale(adult_X_trains[data_idx])\n",
    "        adult_X_test = preprocessing.scale(adult_X_tests[data_idx])\n",
    "        adult_Y_train = adult_Y_trains[data_idx]\n",
    "        adult_Y_test = adult_Y_tests[data_idx]\n",
    "        \n",
    "        clf_svm = GridSearchCV(estimator = LinearSVC(), \n",
    "                               param_grid=svm_params_linear,\n",
    "                               return_train_score=True)\n",
    "        clf_svm.fit(adult_X_train,adult_Y_train)\n",
    "\n",
    "        store_acc_param(SVM,ADULT,part_itr,trial_itr,\n",
    "                        clf_svm.best_params_,\n",
    "                        clf_svm.cv_results_['mean_train_score'][clf_svm.best_index_],\n",
    "                        clf_svm.cv_results_['mean_test_score'][clf_svm.best_index_],\n",
    "                        clf_svm.score(adult_X_test,adult_Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T21:47:28.143192Z",
     "start_time": "2018-03-25T21:46:33.155255Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVM on cov dataset\n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        cov_X_train = preprocessing.scale(cov_X_trains[data_idx])\n",
    "        cov_X_test = preprocessing.scale(cov_X_tests[data_idx])\n",
    "        cov_Y_train = cov_Y_trains[data_idx]\n",
    "        cov_Y_test = cov_Y_tests[data_idx]\n",
    "        \n",
    "        clf_svm = GridSearchCV(estimator = LinearSVC(), \n",
    "                               param_grid=svm_params_linear,\n",
    "                               return_train_score=True)\n",
    "        clf_svm.fit(cov_X_train,cov_Y_train)\n",
    "\n",
    "        store_acc_param(SVM,COV,part_itr,trial_itr,\n",
    "                        clf_svm.best_params_,\n",
    "                        clf_svm.cv_results_['mean_train_score'][clf_svm.best_index_],\n",
    "                        clf_svm.cv_results_['mean_test_score'][clf_svm.best_index_],\n",
    "                        clf_svm.score(cov_X_test,cov_Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T21:49:47.613501Z",
     "start_time": "2018-03-25T21:49:28.654583Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVM on letter dataset\n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        letter_X_train = preprocessing.scale(letter_X_trains[data_idx])\n",
    "        letter_X_test = preprocessing.scale(letter_X_tests[data_idx])\n",
    "        letter_Y_train = letter_Y_trains[data_idx]\n",
    "        letter_Y_test = letter_Y_tests[data_idx]\n",
    "        \n",
    "        clf_svm = GridSearchCV(estimator = LinearSVC(), \n",
    "                               param_grid=svm_params_linear,\n",
    "                               return_train_score=True)\n",
    "        clf_svm.fit(letter_X_train,letter_Y_train)\n",
    "\n",
    "        store_acc_param(SVM,LETTER,part_itr,trial_itr,\n",
    "                        clf_svm.best_params_,\n",
    "                        clf_svm.cv_results_['mean_train_score'][clf_svm.best_index_],\n",
    "                        clf_svm.cv_results_['mean_test_score'][clf_svm.best_index_],\n",
    "                        clf_svm.score(letter_X_test,letter_Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T20:56:06.023950Z",
     "start_time": "2018-03-25T20:56:06.017414Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "C_list_lr = [1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1, 1, 10, 100, 1000, 10000] # Different C to try.\n",
    "\n",
    "lr_params = {\n",
    "    'C':C_list_lr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T22:04:13.770276Z",
     "start_time": "2018-03-25T22:04:08.712933Z"
    }
   },
   "outputs": [],
   "source": [
    "# LR on adult dataset \n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        adult_X_train = adult_X_trains[data_idx]\n",
    "        adult_X_test = adult_X_tests[data_idx]\n",
    "        adult_Y_train = adult_Y_trains[data_idx]\n",
    "        adult_Y_test = adult_Y_tests[data_idx]\n",
    "        \n",
    "        clf_lr = GridSearchCV(estimator = LogisticRegression(), \n",
    "                              param_grid=lr_params,\n",
    "                              return_train_score=True)\n",
    "        clf_lr.fit(adult_X_train,adult_Y_train)\n",
    "        \n",
    "        store_acc_param(LR,ADULT,part_itr,trial_itr,\n",
    "                        clf_lr.best_params_,\n",
    "                        clf_lr.cv_results_['mean_train_score'][clf_lr.best_index_],\n",
    "                        clf_lr.cv_results_['mean_test_score'][clf_lr.best_index_],\n",
    "                        clf_lr.score(adult_X_test,adult_Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T04:06:44.084918Z",
     "start_time": "2018-03-26T04:06:34.736407Z"
    }
   },
   "outputs": [],
   "source": [
    "# LR on cov dataset \n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        cov_X_train = cov_X_trains[data_idx]\n",
    "        cov_X_test = cov_X_tests[data_idx]\n",
    "        cov_Y_train = cov_Y_trains[data_idx]\n",
    "        cov_Y_test = cov_Y_tests[data_idx]\n",
    "        \n",
    "        clf_lr = GridSearchCV(estimator = LogisticRegression(), \n",
    "                              param_grid=lr_params,\n",
    "                              return_train_score=True)\n",
    "        clf_lr.fit(cov_X_train,cov_Y_train)\n",
    "        \n",
    "        store_acc_param(LR,COV,part_itr,trial_itr,\n",
    "                        clf_lr.best_params_,\n",
    "                        clf_lr.cv_results_['mean_train_score'][clf_lr.best_index_],\n",
    "                        clf_lr.cv_results_['mean_test_score'][clf_lr.best_index_],\n",
    "                        clf_lr.score(cov_X_test,cov_Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T04:07:43.303463Z",
     "start_time": "2018-03-26T04:07:38.516639Z"
    }
   },
   "outputs": [],
   "source": [
    "# LR on letter dataset \n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        letter_X_train = letter_X_trains[data_idx]\n",
    "        letter_X_test = letter_X_tests[data_idx]\n",
    "        letter_Y_train = letter_Y_trains[data_idx]\n",
    "        letter_Y_test = letter_Y_tests[data_idx]\n",
    "        \n",
    "        clf_lr = GridSearchCV(estimator = LogisticRegression(), \n",
    "                              param_grid=lr_params,\n",
    "                              return_train_score=True)\n",
    "        clf_lr.fit(letter_X_train,letter_Y_train)\n",
    "        \n",
    "        store_acc_param(LR,LETTER,part_itr,trial_itr,\n",
    "                        clf_lr.best_params_,\n",
    "                        clf_lr.cv_results_['mean_train_score'][clf_lr.best_index_],\n",
    "                        clf_lr.cv_results_['mean_test_score'][clf_lr.best_index_],\n",
    "                        clf_lr.score(letter_X_test,letter_Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T04:02:50.924219Z",
     "start_time": "2018-03-26T04:02:50.916015Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "NUM_TREES=[200]\n",
    "NUM_FEATURES=[1,2,4,6,8,12,16,20]\n",
    "rf_params = {\n",
    "    'n_estimators':NUM_TREES,\n",
    "    'max_features':NUM_FEATURES\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T04:13:26.550701Z",
     "start_time": "2018-03-26T04:10:20.973854Z"
    }
   },
   "outputs": [],
   "source": [
    "# RF on adult dataset \n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        adult_X_train = adult_X_trains[data_idx]\n",
    "        adult_X_test = adult_X_tests[data_idx]\n",
    "        adult_Y_train = adult_Y_trains[data_idx]\n",
    "        adult_Y_test = adult_Y_tests[data_idx]\n",
    "        \n",
    "        clf_rf = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "                              param_grid=rf_params,\n",
    "                              return_train_score=True)\n",
    "        clf_rf.fit(adult_X_train,adult_Y_train)\n",
    "        \n",
    "        store_acc_param(RF,ADULT,part_itr,trial_itr,\n",
    "                        clf_rf.best_params_,\n",
    "                        clf_rf.cv_results_['mean_train_score'][clf_rf.best_index_],\n",
    "                        clf_rf.cv_results_['mean_test_score'][clf_rf.best_index_],\n",
    "                        clf_rf.score(adult_X_test,adult_Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T04:18:18.617122Z",
     "start_time": "2018-03-26T04:14:20.477795Z"
    }
   },
   "outputs": [],
   "source": [
    "# RF on cov dataset \n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        cov_X_train = cov_X_trains[data_idx]\n",
    "        cov_X_test = cov_X_tests[data_idx]\n",
    "        cov_Y_train = cov_Y_trains[data_idx]\n",
    "        cov_Y_test = cov_Y_tests[data_idx]\n",
    "        \n",
    "        clf_rf = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "                              param_grid=rf_params,\n",
    "                              return_train_score=True)\n",
    "        clf_rf.fit(cov_X_train,cov_Y_train)\n",
    "        \n",
    "        store_acc_param(RF,COV,part_itr,trial_itr,\n",
    "                        clf_rf.best_params_,\n",
    "                        clf_rf.cv_results_['mean_train_score'][clf_rf.best_index_],\n",
    "                        clf_rf.cv_results_['mean_test_score'][clf_rf.best_index_],\n",
    "                        clf_rf.score(cov_X_test,cov_Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-26T04:41:31.398Z"
    }
   },
   "outputs": [],
   "source": [
    "# RF on letter dataset \n",
    "for part_itr in range(NUM_PARTITIONS):\n",
    "    for trial_itr in range(NUM_TRIALS):\n",
    "        data_idx = trial_itr * 3 + part_itr\n",
    "        \n",
    "        # extract input data from input data table\n",
    "        letter_X_train = letter_X_trains[data_idx]\n",
    "        letter_X_test = letter_X_tests[data_idx]\n",
    "        letter_Y_train = letter_Y_trains[data_idx]\n",
    "        letter_Y_test = letter_Y_tests[data_idx]\n",
    "        \n",
    "        clf_rf = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "                              param_grid={\n",
    "                                'n_estimators':NUM_TREES,\n",
    "                                'max_features':[1,2,4,6,8,12,16]\n",
    "                              },\n",
    "                              return_train_score=True)\n",
    "        clf_rf.fit(letter_X_train,letter_Y_train)\n",
    "        \n",
    "        store_acc_param(RF,LETTER,part_itr,trial_itr,\n",
    "                        clf_rf.best_params_,\n",
    "                        clf_rf.cv_results_['mean_train_score'][clf_rf.best_index_],\n",
    "                        clf_rf.cv_results_['mean_test_score'][clf_rf.best_index_],\n",
    "                        clf_rf.score(letter_X_test,letter_Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T04:14:16.318401Z",
     "start_time": "2018-03-26T04:14:16.308320Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump raw accuracies & best_params to csv files\n",
    "np.save('best_params_4.npy',BEST_PARAM_TABLE)\n",
    "np.save('accuracies_4.npy',ACCU_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Outputs & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "150"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "225px",
    "left": "1070px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
